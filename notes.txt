
new functions in  mptcp 4.14
### 

- tcp_mstamp_refresh > 
- tcp_time_stamp_raw

### Fast retransmit

left_out is number of segments left network, but not ACKed yet.

net.ipv4.tcp_sack

- snd.fack holds the forward-most data held by the receiver
- tcp_is_fack requires sack != tcp_is_reno

undo_cwnd
http://www.brendangregg.com/blog/2014-09-06/linux-ftrace-tcp-retransmit-tracing.html
- tcp_fastretrans_alert -> maybe that's what we should use
- tcp_time_to_recover : decides that a loss is caused by a 
- tcp_dupack_heuristics: true if sacked_out and 

int tcp_reordering = sock_net(sk)->ipv4.sysctl_tcp_reordering;
Le check pour une perte est bien > tp->reordering


https://wiki.aalto.fi/download/attachments/69901948/TCP-CongestionControlFinal.pdf

 * tcp_fastretrans_alert() is entered:
 * - each incoming ACK, if state is not "Open"
 * - when arrived ACK is unusual, namely:
 *	* SACK
 *	* Duplicate ACK.
 *	* ECN ECE.

Retransmission of
a data packet is always followed by placing a copy of that
data packet in a retransmission queue.  The reception of an
ACK then results to removing related copies in the retrans-
mission queue. In current kernel the retransmission queue is
defined as a member of
struct sock
and under the name
write queue
.
there are three tag bits,  to mark packets in re-
transmission queue: SACKED (S), RETRANS (R) and LOST
(L). Packets in queue with these bits set are counted in vari-
ables sacked_out , retrans_out and lost_out

=== Negociatition ===

tcp_timestamps
1=random offset
2=enabled
3=wallclock + random offset
4=wallclock

tcp_timestamps_precision = look for TCP_TSEXT_PRECISION_MS (1)

tcp_ack_update_rtt

tcp_transmit_skb adds the options (either tcp_syn_options or tcp_established)

tp->retrans_stamp is used in syn

struct tcp_options_received {
	long	ts_recent_stamp;/* Time we stored ts_recent (for aging) */
	u32	ts_recent;	/* Time stamp to echo next		*/

In timekeeping.c c la d ou je peux recuperer le temps rapidement


 * when syncookies are in effect and tcp timestamps are enabled we encode
 * tcp options in the lower bits of the timestamp value that will be
 * sent in the syn-ack.
 * Since subsequent timestamps use the normal tcp_time_stamp value, we
 * must make sure that the resulting initial timestamp is <= tcp_time_stamp.

TODO 
- adapt for RTTs tcp_synack_rtt_meas/tcp_update_rtt_min/tcp_rtt_estimator


tcp_v4_syn_recv_sock is called once 3WHS has completed
tcp_synack_rtt_meas
Listening procedure:
tcp_rcv_state_process( "if (sk->sk_state == TCP_NEW_SYN_RECV)" ) -> tcp_conn_request -> tcp_openreq_init



ACK path for mptcp
mptcp_sub_retransmit_timer
mptcp_ack_timer/mptcp_ack_retransmit_timer concern
mptcp_established_options -> mptcp_write_dss_data_ack (used in
		mptcp_save_dss_data_seq and mptcp_options_write)

tcp_options_write calls -> mptcp_options_write

Look at where it's best to reinject is

==== MY ADDITIONS ===
mptcp_send_ack_on_fast_path

==== REINJECTIONS RELATED ===
- mptcp_is_reinjected / MPTCP_REINJECT
- mptcp_reinject_data (appele pour les cas particuliers) -> __mptcp_reinject_data vont reinjecter le paquet dans la
meta->reinject_queue donc pas besoin de les tracer
- mptcp_sub_send_loss_probe -> __mptcp_reinject_data donc pas besoin de tracer
- mptcp_meta_retransmit_timer -> mptcp_retransmit_skb calls -> get_subflow ->
__tcp_push_pending_frames  => on doit le tracer
- seen in mptcp_push_pending_frames
	 "But, MPTCP also checks packets_out, as this is an
	 indication that we might want to do opportunistic reinjection."
- mptcp_write_xmit -> mptcp_skb_entail

> maybe in get_subflow we could 

1/ mptcp_write_xmit demande au scheduler.next_segment() le prochain segment a
envoyer avec la socket a utiliser.
Dans le scheduler par defaut, quand il n'y a plus d'espace dans la snd_wnd de la
meta & different de la reinjection, mptcp_next_segment() dans mptcp_sched.c appelle
mptcp_rcv_buf_optimization qui fait la reinjection opportuniste:

 /* Sets *@reinject to 1 if the returned segment comes from the
 * reinject queue. Sets it to 0 if it is the regular send-head of the meta-sk,
 * and sets it to -1 if it is a meta-level retransmission to optimize the
 * receive-buffer. */

I modified next_segment to return -2 for opportunistic reinjection with penalty.

an skb records on which path it is delivered via mptcp_pi_to_flag(tp->mptcp->path_index) & TCP_SKB_CB(skb)->path_mask;
(see mptcp_dont_reinject_skb)
	checker mptcp_skb_entail et son reinject parameter

I should hook mptcp_skb_entail

We need more choice on where to send the packet

	subsk = meta_tp->mpcb->sched_ops->get_subflow(meta_sk, skb, false);


En fait il ne choisit pas reellement ou reinjecter (aka laisse le scheduler)
In tcp_skb_cb
		__u32 path_mask; /* paths that tried to send this skb */

maybe I should use tcp_send_ack, it is used in a variety of places
mptcp_queue_skbgit diff-tree --check EMPTY HEAD
- __tcp_ack_snd_check
- mptcp_cleanup_rbuf

=== TAIL LOSS PROBE ===
- tlp.patch est un patch a l'envers (git apply -R tlp.patch) mais l'ancetre
n'existe pas dans mon arbre
- 
- tcp_probe_timer
Ajoute send_loss_probe/


=== Schedulers ===
- implementes dans mptcp_rr.c / mptcp_sched.c /
mptcp mptcp_sched_default

- get_subflow_from_selectors permet de choisir le meilleur sous flot
Notamment avec ce check
		if (tp->srtt_us < min_srtt) {
			min_srtt = tp->srtt_us;
			bestsk = sk;
		}

===========
mptcp_queue_skbg is where changes should happen.

> 

Interestingly we have:
/* Quick ACK if more 3/4 of the receive window is filled */
if (after64(tp->mptcp->map_data_seq,
		rcv_nxt64 + 3 * (tcp_receive_window(meta_tp) >> 2)))
	tcp_enter_quickack_mode(sk);

time related mptcp_set_rto

TCP_MAX_QUICKACKS


Les timers sont definies comme 
#define TCP_RTO_MAX	((unsigned)(120*HZ))
tcp_set_rto


static inline u32 __tcp_set_rto(const struct tcp_sock *tp)
{
	return usecs_to_jiffies((tp->srtt_us >> 3) + tp->rttvar_us);
}

This sentence is weird
	 * 1. If rtt variance happened to be less 50msec, it is hallucination.

	 Pour TLP tail loss probe regarder 
	 tcp_schedule_loss_probe

__tcp_ack_snd_check -> mptcp dataack on fastest path

Probes:
- tcp_send_loss_probe


Timers:
...can be seen in tcp_timer.c

- tcp_probe_timer
- tcp_write_timer_handler
- dans inet_connection_sock, on a acces a plusieurs probe_timestamp;
 	struct timer_list	  icsk_retransmit_timer;
 	struct timer_list	  icsk_delack_timer; (la structure a un champ "expires")
	for instance tcp_rearm_rto
inet_csk_clear_xmit_timer
ICSK_TIME_LOSS_PROBE 
inet_csk_reset_xmit_timer

Experience:
Pour voir une amelioration il ne faut pas que le sous-flot soit bcp plus lent
aka si
	if (4 * tp->srtt_us >= tp_it->srtt_us) {
alors on ne reinjecte pas dessus.


MAPPINGS

mptcp_sequence
mptcp_data_ready -> mptcp_validate_mapping

on peut prendre le dataack, regarder pour chaque sous flot si mapping_present == true  et verifier ensuite si le dataack acquitte qque chose dans le mapping courant:

/* Those three fields record the current mapping */
    u64    map_data_seq;
    u32    map_subseq;
    u16    map_data_len;

mais doit y avoir une API pour faire ca ou verifier que le dataack acquitte qque chose de ce sous flot
tout ce que je trouve c mptcp_validate_mapping mais ca envoie des paquets en cas de probleme alors que nous on veut juste regarder

mptcp_clean_rtx_queue

struct tcp_skb_cb {
__u32 path_mask; /* paths that tried to send this skb */
}


Upgrade to newer kernels:
- sysctl_tcp_thin_dupack removed in  2c04ac8ae0b61e0780a30b7069a11bb202b21f26
and 4a7f6009441144783e5925551c72e3f2e1b0839b
- early retransmit removed in bec41a11dd3dc8c54f766b4f494140ca92ba7c10 
(i.e., fast recovery on small inflight with <3 dupacks); it is replaced by RACK.
More specifically when RACK receives DUPACKs, it'll arm a reordering timer to start fast
    recovery after a quarter of (min)RTT, hence it covers the early
    retransmit except RACK does not limit itself to specific inflight
    or dupack numbers.

Implem de francois:

Il ajoute dans la meta:
	u32 mptcp_min_path_owd_in;	/* only set in meta_sk */
	u32 mptcp_min_path_owd_out;	/* only set in meta_sk */
Ensuite il a:
get_virtual_rtt
